{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "710787ef-1eba-48a3-a76d-67ab0ef539a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "deg: 1.0 isolated nodes: 370 avg_degree_total: 0.97\n",
      "\n",
      "lambda= 0.0  t= 159  eps-delta= 2.224418177332228e-08\n",
      "m_init: 0.7859766580538275 ent:  0.1720699495590459\n",
      "lambda= 0.1  t= 130  eps-delta= 2.2140530232519043e-09\n",
      "m_init: 0.7699358367558866 ent:  0.17127259171924963\n",
      "lambda= 0.2  t= 135  eps-delta= 5.178161091479079e-08\n",
      "m_init: 0.7545492129205356 ent:  0.16897079877838897\n",
      "lambda= 0.30000000000000004  t= 138  eps-delta= 3.3195433336565375e-09\n",
      "m_init: 0.7399806499309954 ent:  0.16533606458353123\n",
      "lambda= 0.4  t= 142  eps-delta= 5.081022252839591e-08\n",
      "m_init: 0.7263552613663471 ent:  0.1605754636000715\n",
      "lambda= 0.5  t= 145  eps-delta= 4.151309743083327e-08\n",
      "m_init: 0.7137593656167142 ent:  0.15491615729839237\n",
      "lambda= 0.6000000000000001  t= 149  eps-delta= 5.117577753133058e-08\n",
      "m_init: 0.7022428278329915 ent:  0.14859118078564132\n",
      "lambda= 0.7000000000000001  t= 152  eps-delta= 1.3671754921617162e-08\n",
      "m_init: 0.6918229572378949 ent:  0.14182740343380668\n",
      "lambda= 0.8  t= 156  eps-delta= 9.103118646768448e-09\n",
      "m_init: 0.6824890587925729 ent:  0.1348359237835574\n",
      "lambda= 0.9  t= 160  eps-delta= 2.7980523702563386e-08\n",
      "m_init: 0.6742072244439773 ent:  0.12780494062947345\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 459\u001b[0m\n\u001b[0;32m    456\u001b[0m         chi\u001b[38;5;241m=\u001b[39mnormalize(chi)\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;66;03m#m_init, ent1, ent, counts = BDCM_entropy_procedure(chi, lambdas, T_max)\u001b[39;00m\n\u001b[1;32m--> 459\u001b[0m         m_init[idx][n_rep], ent1[idx][n_rep], ent[idx][n_rep], counts \u001b[38;5;241m=\u001b[39m \u001b[43mBDCM_entropy_procedure_GENERAL_ER\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambdas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_saves\u001b[49m\u001b[43m,\u001b[49m\u001b[43msaving_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;66;03m#np.savez(\"ER_p1.npz\", m_init=m_init, ent1=ent1, ent=ent,nodes_numbers=nodes_numbers, mean_degrees=mean_degrees, max_degrees=max_degrees, deg=deg, prob=prob,mean_degrees_total=mean_degrees_total,nodes_isolated=nodes_isolated, T_max=T_max,num_rep=num_rep)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 371\u001b[0m, in \u001b[0;36mBDCM_entropy_procedure_GENERAL_ER\u001b[1;34m(chi, lambdas, T_max, n_saves, saving_time, start)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(delta\u001b[38;5;241m>\u001b[39meps):\n\u001b[0;32m    369\u001b[0m     chi_copy\u001b[38;5;241m=\u001b[39mchi\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m--> 371\u001b[0m     chi\u001b[38;5;241m=\u001b[39m \u001b[43mBDCM_ER\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdegrees_edges\u001b[49m\u001b[43m,\u001b[49m\u001b[43medges_with_d_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43mN_edges_pos_dm1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mattr_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlmbd_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdamppar\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    373\u001b[0m     delta\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mabs(chi\u001b[38;5;241m-\u001b[39mchi_copy)\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m    374\u001b[0m     t\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[2], line 130\u001b[0m, in \u001b[0;36mBDCM_ER\u001b[1;34m(chi, degrees_edges, edges_with_d_positions, N_edges_pos_dm1, A, p, c, attr_value, lmbd_in, damppar, epsilon)\u001b[0m\n\u001b[0;32m    122\u001b[0m                     idx_mes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m), D\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    123\u001b[0m                                     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(xk)\n\u001b[0;32m    124\u001b[0m                                     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(xi)\n\u001b[0;32m    125\u001b[0m                     )\n\u001b[0;32m    128\u001b[0m                     L[d][idx_rho_D] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m LL[d][idx_rho_Dm1]\u001b[38;5;241m*\u001b[39mchi_local[d][idx_mes][\u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m+\u001b[39m [np\u001b[38;5;241m.\u001b[39mnewaxis] \u001b[38;5;241m*\u001b[39m T)]         \u001b[38;5;66;03m#it creates (slice(None), None, None...) so that we can math the shapes of LL and chi_local[] and do the element wise multiplication\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     LL[d]\u001b[38;5;241m=\u001b[39mL[d]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m#final HPr update\u001b[39;00m\n\u001b[0;32m    133\u001b[0m chi2[d]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros_like(chi[edges_with_d_positions[d]])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#This code is optimized to generate the BDCM entropy plots for majority dynamics always-stay tie breaking on Erdos-Renyi graph.\n",
    "#(with small modifications it can run on any graph with different dynamical rules)\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "\n",
    "#Ising ferromagnet/majority rule, always stay tie breaking\n",
    "def atr_condition(xi,xj,rho,p,c):\n",
    "    if xi[p]==np.sign(rho[p+c-1]+xj[p+c-1]): return(1)\n",
    "    elif (rho[p+c-1]+xj[p+c-1])==0 and xi[p]==xi[p+c-1]: return(1)\n",
    "    else: return(0)\n",
    "        \n",
    "def traj_condition(xi,xj,rho,p,c):\n",
    "    prod=1\n",
    "    for t in range(0,p+c-1):\n",
    "        #if x_i[t+1]==-1*np.sign(np.sum(neighbours[:,t])): continue    #minority dynamics\n",
    "        if xi[t+1]==np.sign(rho[t]+xj[t]): continue    #majority dynamics\n",
    "        elif (rho[t]+xj[t])==0 and xi[t+1]==xi[t]: continue #always-stay tie breaking\n",
    "        #elif np.sum(neighbours[:,t])==0 and x_i[t+1]==-1*x_i[t]: continue #always-change tie breaking\n",
    "        else: \n",
    "            prod=0\n",
    "            break\n",
    "    return(prod)\n",
    "\n",
    "def atr_condition2(xi,rho,p,c):\n",
    "    if xi[p]==np.sign(rho[p+c-1]): return(1)\n",
    "    elif (rho[p+c-1])==0 and xi[p]==xi[p+c-1]: return(1)\n",
    "    else: return(0)\n",
    "        \n",
    "def traj_condition2(xi,rho,p,c):\n",
    "    prod=1\n",
    "    for t in range(0,p+c-1):\n",
    "        #if x_i[t+1]==-1*np.sign(np.sum(neighbours[:,t])): continue    #minority dynamics\n",
    "        if xi[t+1]==np.sign(rho[t]): continue    #majority dynamics\n",
    "        elif (rho[t])==0 and xi[t+1]==xi[t]: continue #always-stay tie breaking\n",
    "        #elif np.sum(neighbours[:,t])==0 and x_i[t+1]==-1*x_i[t]: continue #always-change tie breaking\n",
    "        else: \n",
    "            prod=0\n",
    "            break\n",
    "    return(prod)\n",
    "\n",
    "def m_attr_i(x_i,p,c):\n",
    "    return(np.sum(x[p:])/c)\n",
    "\n",
    "def attr_fix(x_i,p,c,attr_value):\n",
    "    if x_i[p+c-1]==attr_value: return(1)\n",
    "    else: return(0)\n",
    "\n",
    "def A_i_sums(xi,xj,rho,p,c,attr_value,lmbd_in):\n",
    "    return(np.exp(-lmbd_in*xi[0])*atr_condition(xi,xj,rho,p,c)*traj_condition(xi,xj,rho,p,c)*attr_fix(xi,p,c,attr_value))\n",
    "\n",
    "def A_i_sums2(xi,rho,p,c,attr_value,lmbd_in):\n",
    "    return(np.exp(-lmbd_in*xi[0])*atr_condition2(xi,rho,p,c)*traj_condition2(xi,rho,p,c)*attr_fix(xi,p,c,attr_value))\n",
    "\n",
    "def onestep_majority(nodes_with_d_positions,degrees_nodes,N_nodes_pos,s):\n",
    "    sums=np.zeros_like(s)\n",
    "    for d in degrees_nodes:\n",
    "        sums[nodes_with_d_positions[d]]=np.sum(s[N_nodes_pos[d]], axis=1) \n",
    "    return np.sign(2*sums + s)\n",
    "\n",
    "#returns endstate of node values\n",
    "def s_endstate(nodes_with_d_positions,degrees_nodes,N_nodes_pos,s,p,c):\n",
    "    for k in range(p+c-1):\n",
    "        s=onestep_majority(nodes_with_d_positions,degrees_nodes,N_nodes_pos,s)\n",
    "    return(s)\n",
    "\n",
    "def m(s,n):\n",
    "    return(np.sum(s)/n)\n",
    "\n",
    "def normalize(chi):\n",
    "    sum_axes = tuple(range(1, chi.ndim)) #all axes except the first one (first one is the \"2*edges\" one)\n",
    "    return chi/np.sum(chi, axis=sum_axes, keepdims=True)\n",
    "\n",
    "#here we also take into account the all ones attractor (we dont sum through states ending with -1)\n",
    "def BDCM_ER(chi,degrees_edges,edges_with_d_positions,N_edges_pos_dm1,A,p,c,attr_value,lmbd_in,damppar,epsilon):\n",
    "    L = {}\n",
    "    LL = {}\n",
    "    chi_local = {}\n",
    "    chi2 = {}\n",
    "    for d in degrees_edges:  #simplest we can do is do the RRG HPR for every d (later/if needed we can maybe try to do it so that all degrees stuff are updated at once, but this approach probably needs more memory)\n",
    "        if d>0:  #edges (j,i) with 0 messages needed for the BDCM update (j is a leaf) need special treatment(we update them only once at the begining, code below) \n",
    "        \n",
    "            #d is now really the number of messages needed for the BDCM update, but in the RRG it was node degree (so we needed d-1 messages for the update) \n",
    "            #hence: on the RHS we need to use d+1 (e.g. when defining LL)\n",
    "        \n",
    "            #L(number of mes with given d mes needed for the BDCM update (except j), traj. xi, sums traj. rho)\n",
    "            L[d] = np.zeros(([np.array(edges_with_d_positions[d])[0].size]+[2]*T+[d+1]*T))\n",
    "            LL[d] = np.zeros(([np.array(edges_with_d_positions[d])[0].size]+[2]*T+[d+1]*T))\n",
    "            chi_local[d] = chi[N_edges_pos_dm1[d]] #chi_local have all the message values needed for the message ij update in the corresponding ij \"row\"\n",
    "            \n",
    "            #we start(D=1) with just message values and trajectory \"sum\" of just trajectory values (rho_(D=1)=x_k)\n",
    "            for xi in itertools.product([1, 0], repeat=T):\n",
    "                if xi[-1] == attr_value:\n",
    "                    for xk in itertools.product([1, 0], repeat=T):\n",
    "                        if xk[-1] == attr_value:\n",
    "                            LL[d][tuple([slice(None)] + list(xi) + list(xk))] = chi_local[d][tuple([slice(None), 0] + list(xk) + list(xi))] \n",
    "            \n",
    "            for D in range(2,d+1): #we go with D from 1(above), 2, 3,... to d-1 now +1 --see note above (number of neighbours except j)\n",
    "                L[d] = np.zeros_like(LL[d])\n",
    "                for xi in itertools.product([1, 0], repeat=T):\n",
    "                    if xi[-1] == attr_value:\n",
    "                        for xk in itertools.product([1, 0], repeat=T):\n",
    "                            if xk[-1] == attr_value:\n",
    "                                idx_rho_D = tuple([slice(None)]\n",
    "                                                  + list(xi)\n",
    "                                                  + [slice(xk[t], D + xk[t]) for t in range(T)]\n",
    "                                ) #we want to create L values for all messages and xi at once---for all possible rho_D's, rho_D's are stored\n",
    "                                #in the last array positions and for given D we have rho_D = rho_D-1 + xk, so we only access thsose positions\n",
    "                                #that start with at least xk values!! hence slice(xk[t] --we go up D-1 values because that is the maximum for rho we can have for given D (all  previous neighbors were 1))\n",
    "                                # on the RHS we need to match shapes, so we take from 0 to D-1 (there are either zeros, or indeed values that we need from previous D-1)--this is the index idx_rho_Dm1            \n",
    "                                \n",
    "                                idx_rho_Dm1 = tuple([slice(None)]\n",
    "                                                    + list(xi)\n",
    "                                                    + [slice(None, D) for _ in range(T)]\n",
    "                                )\n",
    "                    \n",
    "                                #above we took message from the zeroth neighbor of chi_local, here D-1 takes first, second...\n",
    "                                idx_mes = tuple([slice(None), D-1]\n",
    "                                                + list(xk)\n",
    "                                                + list(xi)\n",
    "                                )\n",
    "                                \n",
    "                                \n",
    "                                L[d][idx_rho_D] += LL[d][idx_rho_Dm1]*chi_local[d][idx_mes][tuple([slice(None)] + [np.newaxis] * T)]         #it creates (slice(None), None, None...) so that we can math the shapes of LL and chi_local[] and do the element wise multiplication\n",
    "                    \n",
    "                LL[d]=L[d].copy()\n",
    "            \n",
    "            #final HPr update\n",
    "            chi2[d]=np.zeros_like(chi[edges_with_d_positions[d]])\n",
    "            for xi in itertools.product([1, 0], repeat=T):\n",
    "                if xi[-1] == attr_value:\n",
    "                    for xj in itertools.product([1, 0], repeat=T):\n",
    "                        chi2[d][tuple([slice(None)] + list(xi) + list(xj))] += np.sum(np.exp(-lmbd_in*(2*xi[0]-1))*A[d][tuple(list(xi) + list(xj))][tuple([np.newaxis] + [slice(None)])] * LL[d][tuple([slice(None)] + list(xi))], axis=tuple(range(1,T+1)))\n",
    "                \n",
    "            \n",
    "            #normalizations of mes + dampening\n",
    "            chi2[d] = np.maximum(chi2[d],epsilon)\n",
    "            chi[edges_with_d_positions[d]] = damppar*normalize(chi2[d]) + (1-damppar)*chi[edges_with_d_positions[d]]\n",
    "\n",
    "    return chi\n",
    "\n",
    "def Zij(chi,num_edg,epsilon):\n",
    "    #we sum products of chi^ij_xixj*chi^ji_xjxi with the right pairs (xi, xj are really the same in both xixj and xjxi) and store this for each edge in Zijs\n",
    "    Zijs=np.zeros(num_edg)\n",
    "    for xi in itertools.product([1, 0], repeat=T):\n",
    "        if xi[-1] == attr_value:\n",
    "            for xj in itertools.product([1, 0], repeat=T):\n",
    "                if xj[-1] == attr_value:\n",
    "                    Zijs += chi[tuple([slice(0,num_edg)] + list(xi) + list(xj))]*chi[tuple([slice(num_edg,2*num_edg)] + list(xj) + list(xi))]\n",
    "\n",
    "    return np.maximum(Zijs,epsilon)\n",
    "\n",
    "def Zi_ER(chi,degrees_nodes,nodes_with_d_positions,N_edges_pos_full,Ai,p,c,N,attr_value,lmbd_in):    \n",
    "    L = {}\n",
    "    LL = {}\n",
    "    chi_neib = {}\n",
    "    Zis = {}\n",
    "    for d in degrees_nodes:  #simplest we can do is do the RRG HPR for every d (later/if needed we can maybe try to do it so that all degrees stuff are updated at once, but this approach probably wastes memory)\n",
    "        if d>0:  #isolated nodes can be ignored\n",
    "        \n",
    "            #d is now really the number of messages needed for the BDCM update, but in the RRG it was node degree (so we needed d-1 messages for the update) \n",
    "            #hence: on the RHS we need to use d+1 (e.g. when defining LL)\n",
    "        \n",
    "            #L(number of mes with given d mes needed for the BDCM update (except j), traj. xi, sums traj. rho)\n",
    "            L[d] = np.zeros(([np.array(nodes_with_d_positions[d]).size]+[2]*T+[d+1]*T))\n",
    "            LL[d] = np.zeros(([np.array(nodes_with_d_positions[d]).size]+[2]*T+[d+1]*T))\n",
    "            chi_neib[d] = chi[N_edges_pos_full[d]] #chi_neib have all the message values needed for the message Zi -all neighboring messages\n",
    "            \n",
    "            #we start(D=1) with just message values and trajectory \"sum\" of just trajectory values (rho_(D=1)=x_k)\n",
    "            for xi in itertools.product([1, 0], repeat=T):\n",
    "                if xi[-1] == attr_value:\n",
    "                    for xk in itertools.product([1, 0], repeat=T):\n",
    "                        if xk[-1] == attr_value:\n",
    "                            LL[d][tuple([slice(None)] + list(xi) + list(xk))] = chi_neib[d][tuple([slice(None), 0] + list(xk) + list(xi))] \n",
    "                \n",
    "            for D in range(2,d+1): #we go with D from 1(above), 2, 3,... up to d (all neib)\n",
    "                L[d] = np.zeros_like(LL[d])\n",
    "                for xi in itertools.product([1, 0], repeat=T):\n",
    "                    if xi[-1] == attr_value:\n",
    "                        for xk in itertools.product([1, 0], repeat=T):\n",
    "                            if xk[-1] == attr_value:\n",
    "                                idx_rho_D = tuple([slice(None)]\n",
    "                                                  + list(xi)\n",
    "                                                  + [slice(xk[t], D + xk[t]) for t in range(T)]\n",
    "                                ) #we want to create L values for all messages and xi at once---for all possible rho_D's, rho_D's are stored\n",
    "                                #in the last array positions and for given D we have rho_D = rho_D-1 + xk, so we only access thsose positions\n",
    "                                #that start with at least xk values!! hence slice(xk[t] --we go up D-1 values because that is the maximum for rho we can have for given D (all  previous neighbors were 1))\n",
    "                                # on the RHS we need to match shapes, so we take from 0 to D-1 (there are either zeros, or indeed values that we need from previous D-1)--this is the index idx_rho_Dm1            \n",
    "                                \n",
    "                                idx_rho_Dm1 = tuple([slice(None)]\n",
    "                                                    + list(xi)\n",
    "                                                    + [slice(None, D) for _ in range(T)]\n",
    "                                )\n",
    "                    \n",
    "                                #above we took message from the zeroth neighbor of chi_local, here D-1 takes first, second...\n",
    "                                idx_mes = tuple([slice(None), D-1]\n",
    "                                                + list(xk)\n",
    "                                                + list(xi)\n",
    "                                )\n",
    "                                \n",
    "                                \n",
    "                                L[d][idx_rho_D] += LL[d][idx_rho_Dm1]*chi_neib[d][idx_mes][tuple([slice(None)] + [np.newaxis] * T)]         #it creates (slice(None), None, None...) so that we can math the shapes of LL and chi_local[] and do the element wise multiplication\n",
    "                    \n",
    "                LL[d]=L[d].copy()\n",
    "            \n",
    "            #finally\n",
    "            Zis[d]=np.zeros(np.array(nodes_with_d_positions[d]).size)\n",
    "            for xi in itertools.product([1, 0], repeat=T):\n",
    "                if xi[-1] == attr_value:\n",
    "                    Zis[d] += np.exp(-lmbd_in*(2*xi[0]-1))*np.sum(Ai[d][tuple(list(xi))][tuple([np.newaxis] + [slice(None)])] * LL[d][tuple([slice(None)] + list(xi))],axis=tuple(range(1,T+1)))\n",
    "        \n",
    "    \n",
    "    Zis_fin =np.zeros(N)\n",
    "    for d in degrees_nodes:\n",
    "        if d>0:\n",
    "            Zis_fin[nodes_with_d_positions[d]] = Zis[d]\n",
    "\n",
    "    return np.maximum(Zis_fin,epsilon)\n",
    "\n",
    "def GENERAL_ERgraph_and_auxialiaryarrays_generation(n,prob,p,c,T,attr_value):\n",
    "    #RANDOM GRAPH GENERATION (General sparse ER) -----------------------------------------------------------------------------------------------\n",
    "    G_first = nx.fast_gnp_random_graph(n, prob)\n",
    "\n",
    "    #it can happen that we have isolated nodes (nodes without neighbors)\n",
    "    isolated_nodes = list(nx.isolates(G_first))\n",
    "    number_iso = len(isolated_nodes) #number of isolated nodes, they just add -lambda_init*number_iso/n to the free entropy densitiy in our case\n",
    "    avg_deg = sum(dict(G_first.degree()).values()) / G_first.number_of_nodes()\n",
    "    \n",
    "    #we remove them (we run BDCM on the parts of G which are not isolated (contibution to phi is done as we stated above))\n",
    "    G = G_first.copy()\n",
    "    G.remove_nodes_from(isolated_nodes)\n",
    "    \n",
    "    G = nx.convert_node_labels_to_integers(G)\n",
    "    N_G_without_isolated = G.number_of_nodes()\n",
    "    num_edg=G.number_of_edges()\n",
    "    adj_matrix = nx.to_numpy_array(G)\n",
    "    \n",
    "    #AUXILIARY ARRAYS ---------------------------------------------------------------------------------------------------------------------\n",
    "    degrees_all = [d for _, d in G.degree()] #for degree i (ith row) we have its degree\n",
    "    degrees_nodes=np.unique(degrees_all) \n",
    "    \n",
    "    #N_nodes is  a dictionary of neighboring nodes, row i containis neighboring nodes of i\n",
    "    N_nodes = {node: list(G.neighbors(node)) for node in G.nodes()}\n",
    "    \n",
    "    edge_dict = {} #edge_dict[(i,j)] returns an index/order in G.edges of the edge (i,j), if (i,j) is a reversed edge (still an edge but not in G.edges) it returns index of (j,i)+num_edges\n",
    "    edges = np.zeros((2*num_edg,2)) #we will have the edges of a graph in an array including the reversed ones in the second half\n",
    "    edges_degree = np.zeros(2*num_edg) #contains number of neighboring edges of edge (i,j) (edges that end in i, except (j,i), second half for reversed edges \n",
    "    for idx, edge in enumerate(G.edges):        \n",
    "        edge_dict[edge] =idx\n",
    "        edge_dict[edge[::-1]] = (idx+num_edg)\n",
    "    \n",
    "        edges[idx]=edge\n",
    "        edges[idx+num_edg]=edge[::-1]\n",
    "    \n",
    "        edges_degree[idx] = degrees_all[edge[0]] -1\n",
    "        edges_degree[idx+num_edg] = degrees_all[edge[1]] -1\n",
    "    edges=edges.astype(int)\n",
    "    edges_degree=edges_degree.astype(int)\n",
    "    \n",
    "    degrees_edges = np.unique(edges_degree)\n",
    "    \n",
    "    #now we create all the auxiliary arrays (like neighboring edges positions and so on), but for node groups with the same degree\n",
    "    A = {}\n",
    "    Ai = {}\n",
    "    N_edges_pos_dm1 = {}\n",
    "    N_edges_pos_full = {}\n",
    "    N_edges_pos_full_marginals = {}\n",
    "    N_nodes_pos = {}\n",
    "    edges_with_d_positions = {}\n",
    "    nodes_with_d_positions = {}\n",
    "    \n",
    "    for d in degrees_edges:\n",
    "        edges_with_d_positions[d] = np.where(edges_degree==d) #positions of edges (i,j) that have d neighboring edges (node i has d+1 neighbors)\n",
    "        \n",
    "        #now we create an array of neigboring edges POSITIONS to an edge (i,j) as they go in G.edges, but in a way where we have edges (k1,i), (k2,i)... where k's are from the neib of i except j! \n",
    "        #we need to know these edges, as they correspond to the messages needed for the BDCM update\n",
    "        N_edges_pos_dm1[d] = np.array(\n",
    "                [[edge_dict[(k, i)] for k in N_nodes[i] if k != j] for i, j in edges[edges_with_d_positions[d]]]\n",
    "        )\n",
    "    \n",
    "        #for the given rule we construct A matrix with factor node A_i values (we could speed up the interations here, but we only go through them once for lmbd_in=0 (!!)\n",
    "        if d>0:\n",
    "            A[d]=np.zeros([2]*T + [2]*T + [d+1]*T)   #A(xi,xj,rho_d), now d is really number of neib edges needed for the BDCM update (d-1 in case of RRG)\n",
    "            for xi in itertools.product([1, 0], repeat=T):\n",
    "                for xj in itertools.product([1, 0], repeat=T):\n",
    "                    for rho in itertools.product(np.arange(d+1), repeat=T):\n",
    "                        A[d][tuple(list(xi) + list(xj) + list(rho))] = A_i_sums(2*np.array(xi)-1,2*np.array(xj)-1,2*np.array(rho)-d,p,c,attr_value,lmbd_in=0)\n",
    "    \n",
    "        \n",
    "    for d in degrees_nodes:\n",
    "        nodes_with_d_positions[d] = np.where(np.array(degrees_all)==d)[0]\n",
    "        #now including the j and only for nodes i (rows correspond to nodes not edges) --we use this when computing Zi and majority dynamics step\n",
    "        N_edges_pos_full[d] = np.array(\n",
    "                [[edge_dict[(k, i)] for k in N_nodes[i]] for i in nodes_with_d_positions[d]]\n",
    "        )\n",
    "    \n",
    "        N_edges_pos_full_marginals[d] = np.array(\n",
    "                [[edge_dict[(i, k)] for k in N_nodes[i]] for i in nodes_with_d_positions[d]]\n",
    "        )\n",
    "    \n",
    "        N_nodes_pos[d] = np.array(\n",
    "                [[k  for k in N_nodes[i]] for i in nodes_with_d_positions[d]]\n",
    "        )\n",
    "    \n",
    "        #also for Zi construction\n",
    "        Ai[d]=np.zeros([2]*T + [d+1]*T)   #A(xi,rho_d)\n",
    "        for xi in itertools.product([1, 0], repeat=T):\n",
    "            for rho in itertools.product(np.arange(d+1), repeat=T):\n",
    "                Ai[d][tuple(list(xi) + list(rho))] = A_i_sums2(2*np.array(xi)-1,2*np.array(rho)-d,p,c,attr_value,lmbd_in=0)\n",
    "\n",
    "    return avg_deg, N_G_without_isolated, number_iso, num_edg, adj_matrix, degrees_all, degrees_nodes, N_nodes, A, Ai, N_edges_pos_dm1, N_edges_pos_full, N_edges_pos_full_marginals, N_nodes_pos, edges_with_d_positions, nodes_with_d_positions, degrees_edges, edges \n",
    "\n",
    "\n",
    "def phi_BP_GENERAL_ER(chi,num_edg,degrees_nodes,nodes_with_d_positions,N_edges_pos_full,Ai,N_G_without_isolated,n,p,c,attr_value,lmbd_in,epsilon, number_iso):\n",
    "    Zis=Zi_ER(chi,degrees_nodes,nodes_with_d_positions,N_edges_pos_full,Ai,p,c,N_G_without_isolated,attr_value,lmbd_in)\n",
    "    Zijs=Zij(chi,num_edg,epsilon)\n",
    "    \n",
    "    return (np.sum(np.log(Zis)) - np.sum(np.log(Zijs)) - lmbd_in*number_iso)/n\n",
    "\n",
    "\n",
    "def avg_m_init_GENERAL_ER(chi,num_edg,degrees_all,edges,n,epsilon,number_iso):\n",
    "    sum=np.zeros(num_edg)\n",
    "    Zijs=np.zeros(num_edg)\n",
    "    for xi in itertools.product([1, 0], repeat=T):\n",
    "        if xi[-1] == attr_value:\n",
    "            for xj in itertools.product([1, 0], repeat=T):\n",
    "                if xj[-1] == attr_value:\n",
    "                    sum += ((2*xi[0]-1)/np.array(degrees_all)[edges[0:num_edg,0]] + (2*xj[0]-1)/np.array(degrees_all)[edges[0:num_edg,1]])*(chi[tuple([slice(0,num_edg)] + list(xi) + list(xj))]*chi[tuple([slice(num_edg,2*num_edg)] + list(xj) + list(xi))])\n",
    "                    Zijs += chi[tuple([slice(0,num_edg)] + list(xi) + list(xj))]*chi[tuple([slice(num_edg,2*num_edg)] + list(xj) + list(xi))]\n",
    "            \n",
    "    Zijs=np.maximum(Zijs,epsilon)\n",
    "    sum=sum/Zijs\n",
    "                    \n",
    "    return (np.sum(sum) + number_iso)/n\n",
    "\n",
    "def BDCM_entropy_procedure_GENERAL_ER(chi, lambdas, T_max,n_saves,saving_time,start):\n",
    "    count=0\n",
    "    counts= 0\n",
    "\n",
    "    ent = np.zeros(lambdas.size)\n",
    "    m_init = np.zeros(lambdas.size)\n",
    "    ent1 = np.zeros(lambdas.size)\n",
    "    \n",
    "    #we go through the range of lambda values (starting at lambda=0 and fixed point from previous lambda value as initial value for mes for next lambda value)\n",
    "    for lmbd_in in lambdas:\n",
    "        if degrees_edges[0]==0:\n",
    "            #first for new lambda, we update leaves messages\n",
    "            d=0 #these are the edges (j,i) where node j is a leaf, hence here the BDCM update is simply just normalized factor node A_j\n",
    "            #so the BDCM update is: \n",
    "            chi_aux=np.zeros_like(chi[edges_with_d_positions[d]])\n",
    "            zero_sum=np.zeros(T)\n",
    "            for xi in itertools.product([1, 0], repeat=T):\n",
    "                if xi[-1] == attr_value:\n",
    "                    for xj in itertools.product([1, 0], repeat=T):\n",
    "                        chi_aux[tuple([slice(None)] + list(xi) + list(xj))] = A_i_sums(2*np.array(xi)-1,2*np.array(xj)-1,zero_sum,p,c,attr_value,lmbd_in)\n",
    "                \n",
    "            #normalizations of mes (dampening is not needed, on leaves we have this exact values unchanging)\n",
    "            chi_aux=normalize(chi_aux)\n",
    "            chi[edges_with_d_positions[d]] = chi_aux\n",
    "    \n",
    "        \n",
    "        delta=1\n",
    "        t=0  \n",
    "        while(delta>eps):\n",
    "            chi_copy=chi.copy()\n",
    "        \n",
    "            chi= BDCM_ER(chi,degrees_edges,edges_with_d_positions,N_edges_pos_dm1,A,p,c,attr_value,lmbd_in,damppar,epsilon)\n",
    "            \n",
    "            delta=np.abs(chi-chi_copy).max()\n",
    "            t+=1\n",
    "            if t>=T_max:\n",
    "                delta=0\n",
    "                counts = lmbd_in\n",
    "                \n",
    "        print(\"lambda=\",lmbd_in,\" t=\",t,\" eps-delta=\",eps-delta)\n",
    "        ent[count] = phi_BP_GENERAL_ER(chi,num_edg,degrees_nodes,nodes_with_d_positions,N_edges_pos_full,Ai,N_G_without_isolated,n,p,c,attr_value,lmbd_in,epsilon, number_iso)     \n",
    "        m_init[count] = avg_m_init_GENERAL_ER(chi,num_edg,degrees_all,edges,n,epsilon,number_iso)\n",
    "        ent1[count] = ent[count] + lmbd_in*m_init[count]\n",
    "        print(\"m_init:\",m_init[count], \"ent: \", ent1[count])\n",
    "\n",
    "        '''\n",
    "        cur_time=time.time()\n",
    "        if ((cur_time-start)>saving_time) and n_saves<1: \n",
    "            print(cur_time-start,\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            #np.savez(\"ER_p1_auto_TEST.npz\", m_init=m_init, ent1=ent1, ent=ent,nodes_numbers=nodes_numbers, mean_degrees=mean_degrees, max_degrees=max_degrees, deg=deg, prob=prob,mean_degrees_total=mean_degrees_total,nodes_isolated=nodes_isolated, T_max=T_max,num_rep=num_rep)\n",
    "            n_saves+=1\n",
    "        '''\n",
    "        if ent1[count]< -0.05: break\n",
    "        if counts>0: break #when counts is non-empty I break the loop, this means that we have hit the lambda for which the mes didnt converge under T_max  steps (and we store in counts this value)\n",
    "            \n",
    "        count+=1\n",
    "\n",
    "\n",
    "    return m_init, ent1, ent, counts\n",
    "\n",
    "\n",
    "#PARAMETERS -----------------------------------------------------------------------------------------------\n",
    "n=1000 #number of nodes \n",
    "#Erdos-Renyi (ER) graph specification:\n",
    "#let deg be the mean node degree: deg=(n-1)*p\n",
    "deg=np.linspace(1,2,3)\n",
    "#deg=np.array([4])\n",
    "prob = deg/(n-1)\n",
    "\n",
    "num_rep=3\n",
    "\n",
    "# (p+c) backtracking attractors\n",
    "p=1\n",
    "c=1\n",
    "T=p+c\n",
    "\n",
    "eps=1e-6 #precision of the converged BDCM messages\n",
    "damppar=0.1\n",
    "attr_value=1\n",
    "epsilon=0 #lowest possible Z_i or Z_ij value and chi mes\n",
    "\n",
    "saving_time=30\n",
    "n_saves=0\n",
    "\n",
    "T_max=1300\n",
    "\n",
    "a=12\n",
    "dl=0.1\n",
    "lambdas=np.linspace(0,a,int(a/dl+1))\n",
    "\n",
    "ent = np.zeros((deg.size,num_rep,lambdas.size))\n",
    "m_init =  np.zeros((deg.size,num_rep,lambdas.size))\n",
    "ent1 =  np.zeros((deg.size,num_rep,lambdas.size))\n",
    "\n",
    "nodes_numbers = np.zeros((deg.size,num_rep))\n",
    "mean_degrees = np.zeros((deg.size,num_rep))\n",
    "max_degrees = np.zeros((deg.size,num_rep))\n",
    "nodes_isolated = np.zeros((deg.size,num_rep))\n",
    "mean_degrees_total = np.zeros((deg.size,num_rep))\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "for idx, _ in enumerate(prob):\n",
    "    for n_rep in range(num_rep):\n",
    "        avg_deg, N_G_without_isolated, number_iso, num_edg, adj_matrix, degrees_all, degrees_nodes, N_nodes, A, Ai, N_edges_pos_dm1, N_edges_pos_full, N_edges_pos_full_marginals, N_nodes_pos, edges_with_d_positions, nodes_with_d_positions, degrees_edges, edges = GENERAL_ERgraph_and_auxialiaryarrays_generation(n,prob[idx],p,c,T,attr_value)\n",
    "        \n",
    "        nodes_isolated[idx][n_rep] = number_iso\n",
    "        mean_degrees[idx][n_rep] = np.mean(degrees_all)\n",
    "        mean_degrees_total[idx][n_rep] = avg_deg\n",
    "        max_degrees[idx][n_rep] = degrees_nodes.max()\n",
    "        print()\n",
    "        print(\"deg:\",deg[idx], \"isolated nodes:\",number_iso, \"avg_degree_total:\",avg_deg)\n",
    "        print()\n",
    "        \n",
    "        #messages-----------------------------------------------\n",
    "        chi=np.random.random(([2*num_edg] + [2]*T + [2]*T))\n",
    "        chi=normalize(chi)\n",
    "        \n",
    "        #m_init, ent1, ent, counts = BDCM_entropy_procedure(chi, lambdas, T_max)\n",
    "        m_init[idx][n_rep], ent1[idx][n_rep], ent[idx][n_rep], counts = BDCM_entropy_procedure_GENERAL_ER(chi, lambdas, T_max,n_saves,saving_time,start)\n",
    "\n",
    "#np.savez(\"ER_p1.npz\", m_init=m_init, ent1=ent1, ent=ent,nodes_numbers=nodes_numbers, mean_degrees=mean_degrees, max_degrees=max_degrees, deg=deg, prob=prob,mean_degrees_total=mean_degrees_total,nodes_isolated=nodes_isolated, T_max=T_max,num_rep=num_rep)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
